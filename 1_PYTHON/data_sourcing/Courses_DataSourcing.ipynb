{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e5163402f9d9e411"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d08fafa574f93eca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Data Sourcing\n",
    "Finding Data\n",
    "I can export it from a software (CSV)\n",
    "I know it exists somewhere in a database (SQL)\n",
    "It's on this website I visit daily (Scraping)\n",
    "I have found a service (API) that gives access to it\n",
    "...\n",
    "Plan\n",
    "Reading/Writing CSV (the hard way)\n",
    "Consuming an API\n",
    "Scraping a website\n",
    "Next lectures\n",
    "Databases & SQL\n",
    "CSV\n",
    "A comma-separated values file is a delimited text file that uses a comma to separate values. A CSV file stores tabular data (numbers and text) in plain text. Each line of the file is a data record. Each record consists of one or more fields, separated by commas.\n",
    "Source: Wikipedia\n",
    "Example\n",
    "ðŸ‘‰ On https://people.sc.fsu.edu/~jburkardt, let's look at the addresses.csv\n",
    "%%bash\n",
    "mkdir -p data\n",
    "curl -s https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv > data/addresses.csv\n",
    "cat data/addresses.csv\n",
    "John,Doe,120 jefferson st.,Riverside, NJ, 08075\n",
    "Jack,McGinnis,220 hobo Av.,Phila, PA,09119\n",
    "\"John \"\"Da Man\"\"\",Repici,120 Jefferson St.,Riverside, NJ,08075\n",
    "Stephen,Tyler,\"7452 Terrace \"\"At the Plaza\"\" road\",SomeTown,SD, 91234\n",
    ",Blankman,,SomeTown, SD, 00298\n",
    "\"Joan \"\"the bone\"\", Anne\",Jet,\"9th, at Terrace plc\",Desert City,CO,00123\n",
    "CSV Reading\n",
    "import csv\n",
    "\n",
    "with open('data/addresses.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, skipinitialspace=True)\n",
    "    for row in reader:\n",
    "        # row is a `list`\n",
    "        print(row)\n",
    "['John', 'Doe', '120 jefferson st.', 'Riverside', 'NJ', '08075']\n",
    "['Jack', 'McGinnis', '220 hobo Av.', 'Phila', 'PA', '09119']\n",
    "['John \"Da Man\"', 'Repici', '120 Jefferson St.', 'Riverside', 'NJ', '08075']\n",
    "['Stephen', 'Tyler', '7452 Terrace \"At the Plaza\" road', 'SomeTown', 'SD', '91234']\n",
    "['', 'Blankman', '', 'SomeTown', 'SD', '00298']\n",
    "['Joan \"the bone\", Anne', 'Jet', '9th, at Terrace plc', 'Desert City', 'CO', '00123']\n",
    "CSV with Headers\n",
    "%%bash\n",
    "curl -s https://people.sc.fsu.edu/~jburkardt/data/csv/biostats.csv > data/biostats.csv\n",
    "head -n 3 data/biostats.csv\n",
    "\"Name\",     \"Sex\", \"Age\", \"Height (in)\", \"Weight (lbs)\"\n",
    "\"Alex\",       \"M\",   41,       74,      170\n",
    "\"Bert\",       \"M\",   42,       68,      166\n",
    "CSV with Headers\n",
    "import csv\n",
    "\n",
    "with open('data/biostats.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, skipinitialspace=True)\n",
    "    for row in reader:\n",
    "         # row is a dict\n",
    "        print(row['Name'], row['Sex'], int(row['Age']))\n",
    "Alex M 41\n",
    "Bert M 42\n",
    "Carl M 32\n",
    "Dave M 39\n",
    "Elly F 30\n",
    "Fran F 33\n",
    "Gwen F 26\n",
    "Hank M 30\n",
    "Ivan M 53\n",
    "Jake M 32\n",
    "Kate F 47\n",
    "Luke M 34\n",
    "Myra F 23\n",
    "Neil M 36\n",
    "Omar M 38\n",
    "Page F 31\n",
    "Quin M 29\n",
    "Ruth F 28\n",
    "Writing a CSV\n",
    "beatles = [\n",
    "    { 'first_name': 'John', 'last_name': 'lennon', 'instrument': 'guitar'},\n",
    "    { 'first_name': 'Ringo', 'last_name': 'Starr', 'instrument': 'drums'}\n",
    "]\n",
    "import csv\n",
    "\n",
    "with open('data/beatles.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=beatles[0].keys())\n",
    "    writer.writeheader()\n",
    "    for beatle in beatles:\n",
    "          writer.writerow(beatle)\n",
    "%%bash\n",
    "cat data/beatles.csv\n",
    "first_name,last_name,instrument\n",
    "John,lennon,guitar\n",
    "Ringo,Starr,drums\n",
    "API\n",
    "An application programming interface (API) is an interface or communication protocol between a client and a server intended to simplify the building of client-side software. It has been described as a â€œcontractâ€ between the client and the server.\n",
    "Source Wikipedia\n",
    "HTTP\n",
    "A client-server protocol based on a request/response cycle.\n",
    "Modern Web API\n",
    "RESTful (GET, POST, etc.)\n",
    "Returns JSON\n",
    "ðŸ‘‰ Examples\n",
    "Requests: HTTP for Humansâ„¢\n",
    "ðŸ‘‰ Documentation\n",
    "Basic request\n",
    "import requests\n",
    "\n",
    "url = 'https://api.github.com/users/ssaunier'\n",
    "response = requests.get(url).json()\n",
    "\n",
    "print(response['name'])\n",
    "SÃ©bastien Saunier\n",
    "Example\n",
    "Let's use the Open Library Books API.\n",
    "This API documentation is not that good - let's decipher it together!\n",
    "Query Parameters:\n",
    "Provide an ISBN (bibkeys)\n",
    "Options:\n",
    "format=json\n",
    "jscmd=data\n",
    "Livecode: Let's find the book title behind ISBN 9780747532699\n",
    "import requests\n",
    "\n",
    "isbn = '0-7475-3269-9'\n",
    "key = f'ISBN:{isbn}'\n",
    "\n",
    "response = requests.get(\n",
    "    'https://openlibrary.org/api/books',\n",
    "    params={'bibkeys': key, 'format':'json', 'jscmd':'data'},\n",
    ").json()\n",
    "\n",
    "print(response[key]['title'])\n",
    "Harry Potter and the Philosopher's Stone\n",
    "Web Scraping\n",
    "HTTP (again)\n",
    "This time, we'll have to deal with HTML (~unstructured data)\n",
    "HTTP website example\n",
    "\n",
    "What does that HTML look like?\n",
    "Right click -> Inspect Element on any website\n",
    "Typically has a tree-like structure\n",
    "\n",
    "HTML Vocabulary\n",
    "\n",
    "BeautifulSoup\n",
    "The Python package to browse HTML (and XML!)\n",
    "ðŸ‘‰ Documentation\n",
    "Typical Web Scraper with BeautifulSoup\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# You now can query the `soup` object!\n",
    "soup.title.string\n",
    "soup.find('h1')\n",
    "soup.find_all('a')\n",
    "# etc...\n",
    "Searching by element name\n",
    "\n",
    "<p>A paragraph</p>\n",
    "\n",
    "<article>An article...</article>\n",
    "<article>Another...</article>\n",
    "paragraph = soup.find(\"p\")\n",
    "articles = soup.find_all(\"article\")\n",
    "Searching by id\n",
    "\n",
    "<a href=\"https://www.lewagon.com\" id=\"wagon\">Le Wagon</a>\n",
    "item = soup.find(id=\"wagon\")\n",
    "Searching by CSS Class\n",
    "\n",
    "<ul>\n",
    "  <li class=\"pizza\">Margharita</li>\n",
    "  <li class=\"pizza\">Calzone</li>\n",
    "  <li class=\"pizza\">Romana</li>\n",
    "  <li class=\"dessert\">Tiramisu</li>\n",
    "</ul>\n",
    "items = soup.find_all(\"li\", class_=\"pizza\")\n",
    "Live-code\n",
    "Let's scrape IMDb Top 50 and extract the following information for each movie:\n",
    "Title\n",
    "Duration\n",
    "Let's build a list (movies) of dict ({ 'title': ?, 'duration': ? })\n",
    "ðŸ’¡ Hint: IMDB requires the headers Accept-Language (to prevent auto-translation based on your IP address) and User-Agent (not to reject your scraping attempts).\n",
    "Solution\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:126.0) Gecko/20100101 Firefox/126.0\",\n",
    "    \"Accept-Language\":\"en-US\"\n",
    "}\n",
    "response = requests.get(\"https://www.imdb.com/list/ls055386972/\", headers=headers)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "movies = []\n",
    "for movie in soup.find_all(\"li\", class_=\"ipc-metadata-list-summary-item\"):\n",
    "    title = movie.find(\"h3\", class_=\"ipc-title__text\").text.split(\". \")[1]\n",
    "    duration = movie.find(\"div\", class_=\"dli-title-metadata\").find_all('span')[1].text\n",
    "    movies.append({\"title\": title, \"duration\": duration})\n",
    "\n",
    "print(movies[0:2])\n",
    "[{'title': 'The Godfather', 'duration': '2h 55m'}, {'title': \"Schindler's List\", 'duration': '3h 15m'}]\n",
    "Bonus\n",
    "image.png\n",
    "Then convert cURL command to Python Requests\n",
    "Your turn!\n",
    "There are 3 challenges for this lecture:\n",
    "Reading and writing CSVs (the hard way!)\n",
    "Making API calls with Python\n",
    "Scraping a website\n",
    "(Optional) Scraping a JavaScript client-side rendered website"
   ],
   "id": "4017a76c1e0e3389"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data Sourcing\n",
    "Finding Data\n",
    "I can export it from a software (CSV)\n",
    "I know it exists somewhere in a database (SQL)\n",
    "It's on this website I visit daily (Scraping)\n",
    "I have found a service (API) that gives access to it\n",
    "...\n",
    "Plan\n",
    "Reading/Writing CSV (the hard way)\n",
    "Consuming an API\n",
    "Scraping a website\n",
    "Next lectures\n",
    "Databases & SQL\n",
    "CSV\n",
    "A comma-separated values file is a delimited text file that uses a comma to separate values. A CSV file stores tabular data (numbers and text) in plain text. Each line of the file is a data record. Each record consists of one or more fields, separated by commas.\n",
    "Source: Wikipedia\n",
    "Example\n",
    "ðŸ‘‰ On https://people.sc.fsu.edu/~jburkardt, let's look at the addresses.csv\n",
    "%%bash\n",
    "mkdir -p data\n",
    "curl -s https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv > data/addresses.csv\n",
    "cat data/addresses.csv\n",
    "John,Doe,120 jefferson st.,Riverside, NJ, 08075\n",
    "Jack,McGinnis,220 hobo Av.,Phila, PA,09119\n",
    "\"John \"\"Da Man\"\"\",Repici,120 Jefferson St.,Riverside, NJ,08075\n",
    "Stephen,Tyler,\"7452 Terrace \"\"At the Plaza\"\" road\",SomeTown,SD, 91234\n",
    ",Blankman,,SomeTown, SD, 00298\n",
    "\"Joan \"\"the bone\"\", Anne\",Jet,\"9th, at Terrace plc\",Desert City,CO,00123\n",
    "CSV Reading\n",
    "import csv\n",
    "\n",
    "with open('data/addresses.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, skipinitialspace=True)\n",
    "    for row in reader:\n",
    "        # row is a `list`\n",
    "        print(row)\n",
    "['John', 'Doe', '120 jefferson st.', 'Riverside', 'NJ', '08075']\n",
    "['Jack', 'McGinnis', '220 hobo Av.', 'Phila', 'PA', '09119']\n",
    "['John \"Da Man\"', 'Repici', '120 Jefferson St.', 'Riverside', 'NJ', '08075']\n",
    "['Stephen', 'Tyler', '7452 Terrace \"At the Plaza\" road', 'SomeTown', 'SD', '91234']\n",
    "['', 'Blankman', '', 'SomeTown', 'SD', '00298']\n",
    "['Joan \"the bone\", Anne', 'Jet', '9th, at Terrace plc', 'Desert City', 'CO', '00123']\n",
    "CSV with Headers\n",
    "%%bash\n",
    "curl -s https://people.sc.fsu.edu/~jburkardt/data/csv/biostats.csv > data/biostats.csv\n",
    "head -n 3 data/biostats.csv\n",
    "\"Name\",     \"Sex\", \"Age\", \"Height (in)\", \"Weight (lbs)\"\n",
    "\"Alex\",       \"M\",   41,       74,      170\n",
    "\"Bert\",       \"M\",   42,       68,      166\n",
    "CSV with Headers\n",
    "import csv\n",
    "\n",
    "with open('data/biostats.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, skipinitialspace=True)\n",
    "    for row in reader:\n",
    "         # row is a dict\n",
    "        print(row['Name'], row['Sex'], int(row['Age']))\n",
    "Alex M 41\n",
    "Bert M 42\n",
    "Carl M 32\n",
    "Dave M 39\n",
    "Elly F 30\n",
    "Fran F 33\n",
    "Gwen F 26\n",
    "Hank M 30\n",
    "Ivan M 53\n",
    "Jake M 32\n",
    "Kate F 47\n",
    "Luke M 34\n",
    "Myra F 23\n",
    "Neil M 36\n",
    "Omar M 38\n",
    "Page F 31\n",
    "Quin M 29\n",
    "Ruth F 28\n",
    "Writing a CSV\n",
    "beatles = [\n",
    "    { 'first_name': 'John', 'last_name': 'lennon', 'instrument': 'guitar'},\n",
    "    { 'first_name': 'Ringo', 'last_name': 'Starr', 'instrument': 'drums'}\n",
    "]\n",
    "import csv\n",
    "\n",
    "with open('data/beatles.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=beatles[0].keys())\n",
    "    writer.writeheader()\n",
    "    for beatle in beatles:\n",
    "          writer.writerow(beatle)\n",
    "%%bash\n",
    "cat data/beatles.csv\n",
    "first_name,last_name,instrument\n",
    "John,lennon,guitar\n",
    "Ringo,Starr,drums\n",
    "API\n",
    "An application programming interface (API) is an interface or communication protocol between a client and a server intended to simplify the building of client-side software. It has been described as a â€œcontractâ€ between the client and the server.\n",
    "Source Wikipedia\n",
    "HTTP\n",
    "A client-server protocol based on a request/response cycle.\n",
    "Modern Web API\n",
    "RESTful (GET, POST, etc.)\n",
    "Returns JSON\n",
    "ðŸ‘‰ Examples\n",
    "Requests: HTTP for Humansâ„¢\n",
    "ðŸ‘‰ Documentation\n",
    "Basic request\n",
    "import requests\n",
    "\n",
    "url = 'https://api.github.com/users/ssaunier'\n",
    "response = requests.get(url).json()\n",
    "\n",
    "print(response['name'])\n",
    "SÃ©bastien Saunier\n",
    "Example\n",
    "Let's use the Open Library Books API.\n",
    "This API documentation is not that good - let's decipher it together!\n",
    "Query Parameters:\n",
    "Provide an ISBN (bibkeys)\n",
    "Options:\n",
    "format=json\n",
    "jscmd=data\n",
    "Livecode: Let's find the book title behind ISBN 9780747532699\n",
    "import requests\n",
    "\n",
    "isbn = '0-7475-3269-9'\n",
    "key = f'ISBN:{isbn}'\n",
    "\n",
    "response = requests.get(\n",
    "    'https://openlibrary.org/api/books',\n",
    "    params={'bibkeys': key, 'format':'json', 'jscmd':'data'},\n",
    ").json()\n",
    "\n",
    "print(response[key]['title'])\n",
    "Harry Potter and the Philosopher's Stone\n",
    "Web Scraping\n",
    "HTTP (again)\n",
    "This time, we'll have to deal with HTML (~unstructured data)\n",
    "HTTP website example\n",
    "\n",
    "What does that HTML look like?\n",
    "Right click -> Inspect Element on any website\n",
    "Typically has a tree-like structure\n",
    "\n",
    "HTML Vocabulary\n",
    "\n",
    "BeautifulSoup\n",
    "The Python package to browse HTML (and XML!)\n",
    "ðŸ‘‰ Documentation\n",
    "Typical Web Scraper with BeautifulSoup\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# You now can query the `soup` object!\n",
    "soup.title.string\n",
    "soup.find('h1')\n",
    "soup.find_all('a')\n",
    "# etc...\n",
    "Searching by element name\n",
    "\n",
    "<p>A paragraph</p>\n",
    "\n",
    "<article>An article...</article>\n",
    "<article>Another...</article>\n",
    "paragraph = soup.find(\"p\")\n",
    "articles = soup.find_all(\"article\")\n",
    "Searching by id\n",
    "\n",
    "<a href=\"https://www.lewagon.com\" id=\"wagon\">Le Wagon</a>\n",
    "item = soup.find(id=\"wagon\")\n",
    "Searching by CSS Class\n",
    "\n",
    "<ul>\n",
    "  <li class=\"pizza\">Margharita</li>\n",
    "  <li class=\"pizza\">Calzone</li>\n",
    "  <li class=\"pizza\">Romana</li>\n",
    "  <li class=\"dessert\">Tiramisu</li>\n",
    "</ul>\n",
    "items = soup.find_all(\"li\", class_=\"pizza\")\n",
    "Live-code\n",
    "Let's scrape IMDb Top 50 and extract the following information for each movie:\n",
    "Title\n",
    "Duration\n",
    "Let's build a list (movies) of dict ({ 'title': ?, 'duration': ? })\n",
    "ðŸ’¡ Hint: IMDB requires the headers Accept-Language (to prevent auto-translation based on your IP address) and User-Agent (not to reject your scraping attempts).\n",
    "Solution\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:126.0) Gecko/20100101 Firefox/126.0\",\n",
    "    \"Accept-Language\":\"en-US\"\n",
    "}\n",
    "response = requests.get(\"https://www.imdb.com/list/ls055386972/\", headers=headers)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "movies = []\n",
    "for movie in soup.find_all(\"li\", class_=\"ipc-metadata-list-summary-item\"):\n",
    "    title = movie.find(\"h3\", class_=\"ipc-title__text\").text.split(\". \")[1]\n",
    "    duration = movie.find(\"div\", class_=\"dli-title-metadata\").find_all('span')[1].text\n",
    "    movies.append({\"title\": title, \"duration\": duration})\n",
    "\n",
    "print(movies[0:2])\n",
    "[{'title': 'The Godfather', 'duration': '2h 55m'}, {'title': \"Schindler's List\", 'duration': '3h 15m'}]\n",
    "Bonus\n",
    "image.png\n",
    "Then convert cURL command to Python Requests\n",
    "Your turn!\n",
    "There are 3 challenges for this lecture:\n",
    "Reading and writing CSVs (the hard way!)\n",
    "Making API calls with Python\n",
    "Scraping a website\n",
    "(Optional) Scraping a JavaScript client-side rendered website"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
